## Xuanhong Chen [![visitors](https://visitor-badge.glitch.me/badge?page_id=neuralchen/neuralchen)](https://github.com/JingyunLiang)[![GitHub Followers](https://img.shields.io/github/followers/neuralchen?style=social)](https://github.com/neuralchen)

[Email](mailto:chenxuanhongzju@gmail.com?subject=[GitHub]%20Source%20Han%20Sans) /
[Homepage](https://github.com/neuralchen) /
[Google Scholar](https://scholar.google.com/citations?hl=en&user=3-Hz9BgAAAAJ&view_op=list_works&sortby=pubdate) /
[Github](https://github.com/neuralchen)

I am currently a PhD Student at [Computer Vision Lab](https://vision.ee.ethz.ch/), [ETH ZÃ¼rich](https://ethz.ch/en.html), Switzerland. I am co-supervised by Prof. [Luc Van Gool](https://scholar.google.com/citations?user=TwMib_QAAAAJ&hl=en) and Prof. [Radu Timofte](http://people.ee.ethz.ch/~timofter/). I also work closely with Dr. [Kai Zhang](https://cszn.github.io/). I mainly focus on low-level vision research, especially on image and video restoration, such as
- image/Face Attributes Editing
- image/Image Super Resolution
- image/video denoising
- ...

:rocket:  **News**
- 2022-01-28: Our new paper [VRT](https://github.com/JingyunLiang/VRT) outperforms previous Video SR/deblurring/denoising methods by up to :heart_eyes: **2.16dB**. :heart_eyes:
- 2021-10-20: [SwinIR](https://github.com/JingyunLiang/SwinIR) is awarded the best paper prize in ICCV-AIM2021.
- 2021-08-01: Three papers ([HCFlow](https://github.com/JingyunLiang/HCFlow), [MANet](https://github.com/JingyunLiang/MANet) and [BSRGAN](https://github.com/cszn/BSRGAN)) accepted by ICCV2021.
- 2021-03-29: One paper ([FKP](https://github.com/JingyunLiang/FKP)) accepted by CVPR2021.


ðŸŒ± **Repositories**
|   Topic   |     Title     |    Badge  |
|:---:|:------:|             :--------------------------:                     |
|  transformer-based video restoration   |   [VRT: A Video Restoration Transformer](https://github.com/JingyunLiang/VRT)   |   [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2201.12288)[![GitHub Stars](https://img.shields.io/github/stars/JingyunLiang/VRT?style=social)](https://github.com/JingyunLiang/VRT)[![download](https://img.shields.io/github/downloads/JingyunLiang/VRT/total.svg)](https://github.com/JingyunLiang/VRT/releases)![visitors](https://visitor-badge.glitch.me/badge?page_id=jingyunliang/VRT)[ <a href="https://colab.research.google.com/gist/JingyunLiang/deb335792768ad9eb73854a8efca4fe0#file-vrt-demo-on-video-restoration-ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="google colab logo"></a>](https://colab.research.google.com/gist/JingyunLiang/deb335792768ad9eb73854a8efca4fe0#file-vrt-demo-on-video-restoration-ipynb)   |
|  transformer-based image restoration   |   [SwinIR: Image Restoration Using Swin Transformer](https://github.com/JingyunLiang/SwinIR)   |   [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2108.10257)[![GitHub Stars](https://img.shields.io/github/stars/JingyunLiang/SwinIR?style=social)](https://github.com/JingyunLiang/SwinIR)[![download](https://img.shields.io/github/downloads/JingyunLiang/SwinIR/total.svg)](https://github.com/JingyunLiang/SwinIR/releases)![visitors](https://visitor-badge.glitch.me/badge?page_id=jingyunliang/SwinIR)[ <a href="https://colab.research.google.com/gist/JingyunLiang/a5e3e54bc9ef8d7bf594f6fee8208533/swinir-demo-on-real-world-image-sr.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="google colab logo"></a>](https://colab.research.google.com/gist/JingyunLiang/a5e3e54bc9ef8d7bf594f6fee8208533/swinir-demo-on-real-world-image-sr.ipynb)   |
|   real-world image SR  |   [Designing a Practical Degradation Model for Deep Blind Image Super-Resolution, ICCV2021](https://github.com/cszn/bsrgan) |   [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2103.14006)[![GitHub Stars](https://img.shields.io/github/stars/cszn/BSRGAN?style=social)](https://github.com/cszn/BSRGAN)![visitors](https://visitor-badge.glitch.me/badge?page_id=cszn/BSRGAN)   |
|  normalizing flow-based image SR and image rescaling   |   [Hierarchical Conditional Flow: A Unified Framework for Image Super-Resolution and Image Rescaling, ICCV2021](https://github.com/JingyunLiang/HCFlow)   |  [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2108.05301)[![GitHub Stars](https://img.shields.io/github/stars/JingyunLiang/HCFlow?style=social)](https://github.com/JingyunLiang/HCFlow)[![download](https://img.shields.io/github/downloads/JingyunLiang/HCFlow/total.svg)](https://github.com/JingyunLiang/HCFlow/releases)[ <a href="https://colab.research.google.com/gist/JingyunLiang/cdb3fef89ebd174eaa43794accb6f59d/hcflow-demo-on-x8-face-image-sr.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="google colab logo"></a>](https://colab.research.google.com/gist/JingyunLiang/cdb3fef89ebd174eaa43794accb6f59d/hcflow-demo-on-x8-face-image-sr.ipynb)   |
|  blind image SR   |   [Mutual Affine Network for Spatially Variant Kernel Estimation in Blind Image Super-Resolution, ICCV2021](https://github.com/JingyunLiang/MANet)  |  [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2108.05302)[![GitHub Stars](https://img.shields.io/github/stars/JingyunLiang/MANet?style=social)](https://github.com/JingyunLiang/MANet)[![download](https://img.shields.io/github/downloads/JingyunLiang/MANet/total.svg)](https://github.com/JingyunLiang/MANet/releases)[ <a href="https://colab.research.google.com/gist/JingyunLiang/4ed2524d6e08343710ee408a4d997e1c/manet-demo-on-spatially-variant-kernel-estimation.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="google colab logo"></a>](https://colab.research.google.com/gist/JingyunLiang/4ed2524d6e08343710ee408a4d997e1c/manet-demo-on-spatially-variant-kernel-estimation.ipynb)   |
|  blind image SR  |  [Flow-based Kernel Prior with Application to Blind Super-Resolution, CVPR2021](https://github.com/JingyunLiang/FKP)   |  [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2103.15977)[![GitHub Stars](https://img.shields.io/github/stars/JingyunLiang/FKP?style=social)](https://github.com/JingyunLiang/FKP)   |
|  image/ video restoration  |  [Image/ Video Restoration Toolbox](https://github.com/cszn/KAIR)   |  [![GitHub Stars](https://img.shields.io/github/stars/cszn/KAIR?style=social)](https://github.com/cszn/KAIR)[![download](https://img.shields.io/github/downloads/cszn/KAIR/total.svg)](https://github.com/JingyunLiang/VRT/releases)[![GitHub Forks](https://img.shields.io/github/forks/cszn/KAIR?style=social)](https://github.com/cszn/KAIR)![visitors](https://visitor-badge.glitch.me/badge?page_id=cszn/KAIR)   |
